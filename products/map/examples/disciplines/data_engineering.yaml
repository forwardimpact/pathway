# yaml-language-server: $schema=https://www.forwardimpact.team/schema/json/discipline.schema.json

specialization: Data Engineering
roleTitle: Data Engineer
isProfessional: true
# null = allow trackless (generalist)
validTracks:
  - null
  - platform
  - sre

# Shared content (human and agent)
description:
  Designs and builds data integration, storage systems, and data infrastructure
  to enable analytics and AI. Masters the art of gaining access to enterprise
  data and making it usable.

# Derivation inputs
coreSkills:
  - data_modeling
  - architecture_design
  - cloud_platforms
supportingSkills:
  - code_quality
  - full_stack_development
  - devops
  - sre_practices
broadSkills:
  - stakeholder_management
  - technical_writing
  - team_collaboration
behaviourModifiers:
  systems_thinking: 1
  outcome_ownership: 1
  relentless_curiosity: 1

# Human-specific content
human:
  professionalRoleSummary:
    We are seeking a skilled {roleTitle} who will design and build data
    integration, storage systems, and data infrastructure that enable analytics
    and AI capabilities. In this role, you will master the art of gaining access
    to enterprise data and making it usable for decision-making across the
    organization.
  managementRoleSummary:
    We are seeking an experienced {specialization} leader to build and lead
    high-performing data engineering teams. In this role, you will drive the
    strategic direction of our data infrastructure while developing talent and
    ensuring data capabilities meet business needs. You will champion data
    quality, governance, and the democratization of data across the
    organization.

# Agent-specific content
agent:
  identity: |
    You are a {roleTitle} agent. Your focus is designing and building
    data integration, storage systems, and data infrastructure that
    enables analytics and AI capabilities. You treat checklists the
    way surgeons and pilots doâ€”not as a crutch, but as a discipline
    that catches the errors expertise alone cannot prevent.
  priority: |
    Data quality is paramount. Always validate data at ingestion points and
    document schema assumptions. Treat undocumented schemas with suspicion.
  constraints:
    - Ignoring data quality issues
    - Creating pipelines without proper error handling
    - Undocumented schema changes
    - Tight coupling between data producers and consumers
